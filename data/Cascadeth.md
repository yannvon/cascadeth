# Cascadeth

This document shall outline the inner workings of *cascadeth*, a client supporting the proof-of-stake protocol called Cascade. This proof-of-concept client was built using the go-ethereum client, and adapts the Cascade protocol to work well with the underlying go-ethereum implementation.

##  Longterm plan

- [ ] Find most convenient mapping between eth and cascade. (change both protocols accordingly)
- [x] Core (blockchain / header chain)
- [x] Consensus (creating, signing & verifying blocks)
- [x] Try starting all processes at same time & rely solely on regular propagation -> only need some logging mechanism
- [ ] Adapting blockchain -> add better sidechain management. (persistance, and more)
- [ ] Transmission protocol (propagation, fetching & syncing)
- [ ] Transactions -> can be performed at any time, need to be verified & acknowledged in a block
- [ ] Mining/worker -> include transaction that we see & validate in blocks as ack
- [ ] Processing -> Applying state change after transaction was sufficiently verified (stake)
- [ ] Checkpoints
- [ ] Permission-less
- [ ] State-flux
- [ ] Other optimizations (tune rewards, etc.)

## Introduction

## Ethereum overview



## Cascade FAQ



#### Option 1: Put all blocks in same chain locally, in processing order

##### Pro 

- Locally the same structure can be kept

##### Con

- Exchanging blocks becomes a nightmare, as the local order is different everywhere, the parent links (parentHash) are different everywhere, and we can't use difficulty for sync.

- 

- 

#### [REJECTED] Option 2a: One blockchain, not keeping track of height, allow out of order block imports

##### Pro 

- No need to change blockchain even.

##### Con

- Dropped blocks will never be retransmitted, not even a reliable broadcast mechanism.

#### [REJECTED] Option 2b: One blockchain but no synchronizing, permissonned system, with all peers known.

##### Pro 

- No need to touch downloader. ( I thought)
- No need to create & delete sidechains.

##### Con

- Peers have to start at the exact same time for this to work, and have the full peerset in memory immediately. This is impossible to guarantee, since peer adding and removing is a mostly independent module. 
- Goes against goal of permissionless implementation.
- Not future proof at all.

#### [CURRENT] Option 2c: One blockchain/DAG, with many sidechains.

c1: synchronizing only local chain -> c2: synchronizing all chains

##### Pro 

- Most of the local architecture/db is the same, most modules work in the same way.
- More control.
- Better understanding of system.
- Easier future changes.

##### Con

- Exchanging blocks becomes harder. 
- We need to change blockchain module and keep track of all sidechains.
- Changes to fetching and syncing/downloading.
- Need to spawn more threads, handle that externally but controlled internally.

#### [REJECTED] Option 3: Multiple separate blockchains, one created by each peer

##### Implications

- changing eth66 protocol:
  - different status messages: td is now a vector ?

##### Pro 

- Syncing, Downloading and Fetching can be kept the same.
- 

##### Con

- Changing core and many other modules, as they all rely on single blockchain. : We could keep them and let them have only local chain.
- A new validator means a whole new blockchain: Not really a problem in terms of memory efficiency. List of valid signers can be used to create new chains (for now they can exist from the start.)
- Easier at the start, but might create problems down the line: how can a new validator tell others to keep new chain for his blocks: as soon as a node sees new signature allowed, creates new chain.
- How is state kept between all chains ? New and separate module, insertBlocks can alter that.
- Extremely unclean ! Every chain needs separate db, need so many processes and threads (seperate fetcher, filters, syncer, etc.), does absolutely not scale. Not a good time investment for future, as it will never be good enough for a decent system.
- More changes in backend, config etc. (altough good learning opportunity, very painful)
- Some inner processes (clique snapshot) have big outside effects -> spawning new db's, chains and handlers. Can become very messy.

#### Why do we need ordering for option 2 ? In other words, why should the parents already be imported ?

If we do not have an order, then syncing won't work, as we might already know a future block, but have some missing ones. Eventually we have to request the missing blocks anyways, might as well keep the future blocks in queue until the older ones are received.

#### Why not change broadcast completely and add acks instead of using blocks?

System would not be permission-less anymore, i.e. joining would be harder / impossible. -> We need a mechanism to resend past acks, even if some peers are down. If we allow permissionless, then broadcast algorithm becomes just as complicated as current block distribution.

#### Why do we need downloader/syncing ? 

Mechanism for new peers to join and get the past messages, in order to recreate state.

#### Do we need to sync all chains with one peer ?

UNSURE!  as the original validator of one chain might be offline. (but does that make him count as malicious and then ? )

Big implications, as if syncing only local chain is enough, then we do not need to change td field, which would be big help.

What if we use td and common.Address to snyc specific side chain ? Impossible to know which one is still active -> bad solution, except if we iterate through all of them.









## Cascadeth implementation details

## Overall

- Blocks become simply means of broadcasting acknowledgements of transactions.
- The blockchain becomes the history of acknowledgements, with the idea that a new client can join and verify the validity of transactions by fetching all previous blocks. (through an existing mechanism)
- tx can be sent with invalid funds, will only be approved once enough funds available.
- The chain is actually multiple sidechains branching off after genesis. 
- A checkpoint mechanism can be implemented to regroup chains.
- Sidechains can advance at different speeds -> blockfetcher line 415 removed, check not too old or too young, line 763 again

### Blockchain (Core)

This core component is in charge of handling and storing the blocks in a chain. It leverages the database components, and allows for insertion of blocks, using a corresponding consensus engine.

Changes applied to specifications:

Most changes were applied through the changes in the engine, who verifies which blocks to insert. Notably the new engine allows for old and newer blocks to be inserted.

- IMPORTANT: CHANGE: maintain ordering of import
  - Previous: blocks can be fetched in any order, and old and new blocks will still be imported. Reasoning: If a validator has incorrect parent hash and/or doesn't send a block in the chain, its his problem, as this might simply result in acks being dropped, but no security problem (check?)

##### Changes

- Add new currentBlockByValidator map, to track latest received block for each sidechain.

##### TODO

- [ ] Keep track of height of every side chain (fixed validators for now, every validator has common.Address)
- [ ] Persist all sidechains.
- [ ] Change total difficulty to being a map of addresses to td of that current block.
- [ ] Create side chain accessors (headByValidator, heightByValidator, heightMap -> used for syncing)
- [ ] 

##### Questions:

- do blocks have to be inserted in sequence ? YES
- do we need heightMap or heightVector ? Can height map be transmitted in blocks ?

### Consensus engine

Decides the rules for which header is valid, how to prepare and finalize blocks that have been produced.

#### Changes

- IMPORTANT: consensus engine does NOT prevent multiple of the same number blocks to come through for a single validator. (this might be necessary though in order to prevent spam, and in order to allow clean redistribution of acks)
- 

##### Questions:

- Do blocks have to come in sequence ? (light panic 30s, check last original commit !)

### Transactions 

- Locally ordered (FIFO order ?), by an existing field. If order is not respected, not enough acks might be gathered, and tx might be hanging.

### Checkpoints & Stake flux

TBD

## Ethereum Wire Protocol (package protocols)

I build cascadeth on top of version eth66. As for sync mode I will only support FullSync for now. (other modes are FastSync, LightSync and SnapSync ) 

Thus we use ethHandler instead of snapHandler. (config.SnapshotCache = 0)

With the Ethereum Wire Protocol version eth66, a new Block is first sent to some peers (proportional to the root of the number of peers) and the others only receive an announcement. If after some time they fail to receive the block from other peers, they may request it. This alleviates some network utilization. Note that still n^2 messages are needed, but most of them (announcements) are substantially smaller than full blocks.

#### Timeline

1. Permissionned setting where every peer/validator is present from beginning. Not that we should not need syncing in this context. 
2. Adding checkpoints on top
3. Making it pemissionless -> major changes to downloading and fetching.

### Backend (type Ethereum)

- txPool
- blockchain
- handler,
- etc.

There is also an ethHandler and snapHandler, that handle the respective back-end.

### (full node network) Handler

- SyncMode: fastSync, snapSync, etc.
- Downloader
- BlockFetcher
- TxFetcher
- peers

 -> makes protocols (either eth or snap, whitch then contain more specific handlers)

### Sync

Synchronises blockchain with a peer, by using downloader package. (depends on SyncMode)

##### TODO

- skipped for now

### Handler eth

ethHandler implements the eth.Backend interface to handle the various network packets that are sent as replies or broadcasts.

-> makes use/ forwards packets to fetcher and downloader.

##### Changes

- Disabled sync
- Allow broadcast of all blocks to full set of peers, not subset.
- More debug messages

### Package eth

1. 

#### Downloader 

Part of package: statesync

##### Questions

- How does Clique downloader work without TD field ? Might never use downloader ?
- When does block / header become ancient ?
- Can I forget about syncing for now and work on processing /fetching immediately ? (and add the permissionless part later ?) YES

##### TODO

#### BlockFetcher

In short, the fetcher is in charge of handling blocks received either through propagation or fetched after receiving an announcement. It can be notified by other peers of new blocks/headers as well as their hashes, but it can also directly receive blocks and headers in a queue. It performs most of its operations in a big main loop.

It receives two types of messages: notifications (header/block) or full propagations (header/blocks). One part takes care of requesting/fetching the full payload if after a notification the payload was not obtained through other means. If the node runs a full client, and only a header was received, then the fetching of the body is also scheduled. This operation is called completion. Eventually all fetched and received blocks end up in a queue. The queued blocks are imported if they have not been seen yet, if their parents are already imported and if they are not more than 1 above current chain height.

There is also one component who filters the received header and blocks, such that the requested payloads are kept by the fetcher, while other payloads are returned for other modules to use. (split into unknown, incomplete and complete)

For cascadeth, we need to change the fetcher such that it also fetches older and newer blocks, as with the many side-chains we can't guarantee that all chains grow at the same rate.

Note that so far the chain made sure that blocks are always delivered in order, i.e. their parent is already in the chain/dag. With multiple sidechains the existing mechanism can't guarantee this, without dropping potentially quite a fee packets,  which would then have to be imported by syncing. (?) Hence this restriction was lifted, and now all blocks can be imported irrespective of their parents and age.

This could have implications for chain syncing, but malicious peers who injected too many or not enough blocks are the ones who get punished. (FIXME what if adversary simply reorders packets ? -> both eventually are imported and thus not a problem, as long as we have a perfect link without deletions.)

DOS protection also needs to be adapted, as every validator can produce blocks indefinitely. However, a different kind of protection is added: Too many announcements/blocks in a short sequence can be punished ! (or not ? what about the network stalling and kicking valid peers ?)

##### Questions

- Why does light sequential/concurrent import take so much longer than full ?
- Is it ok to lift "parent known"  & age/height restrictions.

##### Changes

- Remove stale block protection
- Remove block limit from single peer
- Remove restriction to only import if parent already present -> No, but completely drop block if parent not present !
- Allow import of newer blocks (above current, local head) -> this fails most tests (mine included) but allows non-mining nodes to import blocks as well !

##### go-ethereum problems discovered

- can create deadlocks, (in test scenarios only), where queue can't be emptied, since priority is always set as -inf. 

##### TODO 

- Some tests don't work anymore because of line 368 if number > height+1. I removed this to make own tests work every time, as otherwise they could enter deadlock. 
- deadlock when running mix, for unknown reason
- Add new state to chain (height for sidechain) such that blocks can only be received in order, even for sidechains. For now only work in permissionned setting, hence no need right now (as holes will be filled through regular propagation & fetching)

### Validator / block creation



## Multichain attempt

1. Ethereum object needs sidechains and sidechains handlers
2. TEST IF I CAN RUN A SINGLE OTHER HANDLER THAT HANDLES CHAIN ID +1 (in future could be address mod 2^32)
   1. Extremely unclean ! need so many processes and threads, does absolutely not scale
3. Allowed signers/validators are usually read from the (single) block chain, which is hard to do at ceation time. Should engine create sidechains on the go ? 
4. Sidechains by signer address ? Sidechains by id to seperate them ?  

## Permissioned implementation

### 1.06 to 13.06

Debugging for four days: just commenting out chainSyncer does not work, as block fetcher is spawned from there. However, all call to chainSyncer were disabled in the process of debugging and thus I can run syncer loop without triggering sync. (for now this seems an ok solution.)

This tedious process also allowed me to write better scripts.

Worry about broadcast not satisfying necessary guarantees, however it seems that an announcing mechanism is in place.

### meeting 10.06

- each process chooses validator for stake, ie all his fund belong to same validator -> can simply be modeled by one node having multiple accounts, very simple !
- Can we implement a negative balance ? This would be required for us to be able to process confirmed transactions immediately
- If not, we need to keep them in a buffer and execute them as soon as the funds become available
- Also, we only confirm transactions for which the funds are available in the local state, this means we need to keep new incoming transaction in buffer until we can ack them when funds become available.

### 14.06

Finish debugging of block sending. 

Debug other parts, such that all chains can be imported correctly.

Namely: Make sure that the header is always the local chain. This helps to make sure that the time in which we can seal new blocks is right, and also that we order our blocks correctly. This time I feel like I should try understanding the processes more before debugging.

Can we get rid of unconfirmed blocks and add them immediately to main chain ?

### 15.06

- Add check such that only local blocs can be added to canonical chain :) (this prevents mining stop and other errors)
- Prevent reorgs from happening (again would mess with local chain)
- Non mining peer has problem with imports, as own height stays 0.
  - Cascadeth: We need ordering for permissionless syncing. For permissionless case we actually also need it as cascade acks are to be ordered ! Height is local height, which might be 0 if node is not mining. Thus we need some different mechanism.

Known bugs:

- Import if not mining: 

  - Solution short term: Anyone can mine their own blocks for now and thus keep chain growing
  - Solution mid term: Drop ordering requirement and simply drop out of order packets, they can then later be retrieved through syncing.

- Import of out of order blocks

  - Previously out of order blocks (ie. parent not present) were simply discarded and then imported through sync if needed (or other mechanism? do peers announce blocks through different means ? probably not.). two options

    1) keep in queue and keep track of side chain head to make sure we import it at the right time

    2) discard and either implement sync, or other mechanism.

*I need to understand fetcher better* -> done to the degree that I understand that indeed no ordering is guaranteed.



### 16.06

- [ ] Test tx broadcast and tx pool status
- [ ] test whether every miner includes all tx's in their blocks
- [ ] think about way to handle ack's and unconfirmed tx's
- [ ] think about how to process transaction

- Transactions are removed from pool once included in one block: not served to other peers anymore
- work on metrics -> how can we read them? Succeeded !
- Non-local txs are not accepted because they are underpriced.

### meeting 17.06

Broadcast transactions, (ie. make sure they are not removed from pool too early ?) - sounds like a bad idea !

OR read transactions from blocks, and add them to own pool (if not acked yet)

Conclusion:

- broadcast tx fix -> do not read form block now
- collect signatures and add to confirmed
- detach the state from head of local chain 

Either one or two additional data structures to keep unacked and unconfirmed transactions.



### 17.06

- meeting
- debugging underpriced transaction error -> gasPrice is in GWei (ie. 10⁹ or more is required, otherwise one can use --gasprice flag)
- Create new script with debugging option to include node run on VSC.



### 18.06

- [ ] 
- [x] detatch state from latest local block
- [ ] 



- find more occurences of syncing and remove it
- there are two different processes that can change the state: both insertingChain as well as commiting transactions in local blocks. Thus just changing (sidechain)- state has no effect in our case.
- Achieving the same outcome with test script with detached state ! Now missing piece is to process/insert every block and not just canonical chain.

### 20.06

- [x] debug node3, why not consistent state ?
  - [ ] State is read from currentHead and not state accessor. -> same is true for EVM context , receipts etc.
  - [ ] Solution: Update currentHead every time and keep different chain for local block creation ?
- [ ] prevent insert into sidechain

- execution of launch_tx.sh script is successful, ie. returns result as expected !! However, just a subset of all eth functionality of course, hence question on how much I should change/support.

### 21.06

- [x] remove tx reward: actually there are no block rewards but tx fees are distributed to block
- [ ] prevent insert into sidechain

### 22.06

- [ ] upgrade txPool to hold unconfirmed and processable transactions
- [ ] how to include txPool into Processor ? (part of blockchain ?)
- [ ] allow txPool to receive tx multiple times and increase weight of ack accordingly
- [ ] do not immediately process transactions once added to block -> instead check if processable isn't empty both when creating block and when receiving block
- [ ] implement a tx_list that sorts tx by weight of acks.

- can we go negative balance ? (temporarily, we have the guarantee that eventually the person will be positive again !) technically state_object account has balance of type big.Int, hence it could be possible to go negative ! :)

## Proof of stake

txPool has all transactions that have not been acked yet. For now only received through broadcast, later also added from block processing.

ackPool has all transactions that have at least one acknowledgement, and the corresponding weight of those acks. -> Proof of stake priority queue, where weight of acks is priority ? 



#### How do we coordinate the collection of acks?

<img src="eth_backend.png" style="zoom:20%;" />



#### ackList data structure

Worked on briefly but skipped in favor of simpler data structure for now.

<img src="unconfirmed_datastructure.png" style="zoom:20%;" />



### 23.06

- For some reason even non-mining nodes are "mining"/executing incoming transactions.
- Mining nodes are executing same transaction multiple times if it does not pass the first time ?
- Why does even node 3 do mining ?? / executing transactions without processing received blocks
  - YES even if not mining the worker mainLoop commits transactions to the pending state
  - SOLUTION: Add stake only according to local weight
  - ISSUE: transactions are mined/commited twice by mining nodes (not through mainloop)



### 24.06 

- [ ] Fix double mining problem for mining nodes -> if state did not include first transaction it can actually add them to two blocks, forcing others to process them twice as well. 

  - [ ] Is it simply a data race between transaction pool and miner ? Unlikely, this seems to only be able to happen if transactions were mined by other people ?
  - [ ] Where does the miner delete txs from pool ? He shifts them or pops them (txs.Shift() / txs.Pop()) after execution. Or "Removed old pending transaction"
  - [ ] Solution for now: add ack according to local weight only.
- [ ] Fix mining problem for no mining nodes: Why does mainLoop also execute transactions ?
- [ ] Discovered node2 badBlock created after state processing ? Race condition with mining ? (mining processed new transaction inbetween state processing ?

  - [x] start mining with s1 ---------------------- tx1 -----tx2-------------------------------------------- WriteBlockAndState() --- s2
  - [x] --------------------------------------------------------------- Process s1 --- tx ------------
  - [x] NO ! Not a race condition ! Simply the fact that in normal chains the chain creator would be careful to not execute the same transaction twice !
  - [x] Since we mined a different block before, obviously we need to implement checks ourselves to avoid double processing of the same transaction !
  - [ ] PROBLEM: currentState in txPool might not be up to date and cause those errors !
  - [ ] transaction validity was always checked against txPool chain state -> currentBlock and not detached stateRoot !
- [ ] Race condition between new mining task taking state -> at the end the state is applied to state before mining. In the meantime other blocks might have been processed !!!!!!!! AAAARRGGGGGH

  - [ ] mining s1 --commit txs  -- addACK-----------------------------wait until seal ---------------------------- s1' (or s1 if unsuccesful) BUT DO NOT UPDATE STATE
  - [ ] --------------------------------- process block ---- process txs ------ s2 -------------------------------------------------- check for new tx that have enough ack..
  - [ ] SOLUTION: Mining never changes state !
  - [ ] FIXME: If mining is last ACK, then we will never process tx. 
- [ ] Race condition causing insertChain to be called ! -> ERRORS AND PANICS ALL AROUND.
- [ ] Mining the same tx over and over until it is part of state -> then we realize error and "Removed old pending transaction"

### 25.06

- [ ] Create list to ack/include tx in block only once -> delete it from pool once acked. 
  - [ ] Cleaning does not happen quickly (WHEN?)
  - [ ] if we do not keep track all acked that are not yet in state, then we add them back to pool when processing new blocks
- [ ] Improve PoS mechanism: Add ack according to stake ! :)
  - [x] Store genesis state to query stake ? DONE for now
  - [x] Querying state by address is easy, but computing total stake in the system is not. 
  - [x] FOR NOW BAD MAGIC CONSTANT :(
- [ ] REALISATION: Current system is not safe at all: It doesn't prevent double spending / we acknowledge conflicting transaction, since we don't keep unconfirmed transactions in our state !!
- [ ] NEW IDEA: Keep two detached states: one with the state we have acked, one with the state that was confirmed universally ! 



### 27.06

- [x] Keep two detached states !
  - [x] One for acknowledging and one with confirmed transactions
  - [x] Mining changes only ackState, while confirmed transaction changes currentState/stateRoot
  - [x] Change: we now need that unacked transactions still influence ackState ! :)
  - [ ] TODO for cornercase where the last ack we receive is our own mining, we need different mechanism to the include newly confirmed transaction in currentState as well, as otherwise we would just skip it !
  - [x] This prevents double spending / acking a doublespend transaction, which previously was not the case
  - [ ] It also makes acked HashSet useles !!
  - [x] FIXME need to validate new acks with currentState and not ackState ..
  - [ ] TODO new test script / unit test.
  - [ ] WHAT about insufficient balances ?
  - [ ] TODO in txPool we need **ackPendingInsufficientBalance** buffer, as well as **confirmedPendingInsufficientBalanced** and **confirmedPendingByMining** 
- [ ] Give own stake to some validator: How to implement ??

### 28.06

- [x] Remove useless acked HashSet
- [ ] meeting

### meeting 28.6

- [ ] First currency with PoS !
- [ ] Detached state
- [ ] data structure for unconfirmed transactions -> show diagrams
- [ ] Read stake from genesis using the genesis root hash to access db.
- [ ] Fixing many bugs were transactions were acked multiple times -> acked Hash set first, but then currentState
- [ ] Many race conditions had to be fixed -> mining blocks in parallel of receiving new transactions -> might get lost ! thus now two states
- [ ] Verify main validation idea with two different states
- [ ] TODO
  - [ ] Read total stake adaptively
  - [ ] New test script / golang tests 
  - [ ] Cornercase where last ack is our own mining -> Kobi: can we just process it in the same way as a normal block ? :) 
  - [ ] Insufficient balances: txPool we need **ackPendingInsufficientBalance** buffer, as well as **confirmedPendingInsufficientBalanced** and **confirmedPendingByMining** 
  - [ ] How to implement delegating stake: Solving problem of total stake in the system -> How to initialize cleanly ? How to keep track if growing / getting smaller through fees ?
  - [ ] better datastructure for unconfirmed, cleaning it
  - [ ] race conditions txpool currentState

### Testing scenarios needed

- [ ] Double spend
- [ ] tx broadcast doesn't work and tx is known through block only

### meeting results

- [ ] is db concurrent ?
- [ ] is processing concurrent ? might something go wrong if two blocks are processed concurrently.
- [ ] If not we need lock on currentStateRoot.
- [ ] instead of ackStateRoot -> map with addr to nonce, solves inconsistency of funds problem
- [ ] might need to go negative, or buffer

#### New TODO POS

- [ ] change ackStateRoot, to map of sender to nonce (maybe containing tx)
- [ ] clean up unconfirmed once confirmed
- [ ] treat own blocks in the same way as foreign blocks -> in order to avoid race condition, while also avoiding edge case where our ack is the last ack received
- [ ] make sure that block processing is either not concurrent, or then use thread safe currentState
- [ ] Is db concurrent ? make sure we don't write too many useless things
- [ ] go negative balances or use buffer if confirmed transaction 
- [ ] read genesis stake sum

### 29.06

- [ ] read genesis stake sum & discover more race conditions

### 30.06

- [ ] Error case if own ack immediately is enough to verify: will never be added to current state (in old model)



## TODO

- [ ] Prevent block spamming from malicious validators (DOS attack) ? Are all notifications accepted ? Are all blocks fetched ?
- [ ] Make sure that permissioned system has right security guarantees for broadcast.
- [ ] Block fetcher: remove ordering check (must not be too much bigger than current head), such that also non-mining nodes can import blocks. (and allow for async network / time drift)
- [ ] Import out of order blocks, for now we drop them. (either keep them in queue by having head per validator, or have syning)
- [ ] Read transactions from sidechains blocks as well
- [ ] Make all nodes archive nodes: bc.cacheConfig.TrieDirtyDisabled
- [ ] Remove transaction rewards for now
- [ ] Add two datastructures, one for transactions to confirm (txPool?) and one for tx waiting to be processed -> processing needs to check pool and see if new txs can be imported
- [ ] Instead of stateRoot and chaning it everywhere, one could imagine updating currentBlock root. (and reverting previous changes)
- [ ] Solving problem of total stake in the system -> How to initialize cleanly ? How to keep track if growing / getting smaller through fees ?



#### Additional sections

- Interesting email to Kobi about why local blocks get preferred, and new foreign blocks have 50% chance of being used and causing reorg.

## Testing

```powershell
geth init --datadir data-cascade-1 data/genesis-cascade.json
 

geth --datadir data-cascade --networkid 15 --port 30303 --unlock 0x78161ecF55Dc59Bd9E9c5C6620c0eb2Ad3b4d555 --mine --nodiscover

password: private

geth --datadir data-cascade-2 --networkid 15 --port 30304 --unlock 0xBbd5695c790F13b470c44b5950311C8dd24f78E6 --mine --nodiscover --ipcpath gethpipe.ipc

password: private2

geth attach \\.\pipe\geth.ipc
geth attach \\.\pipe\gethpipe.ipc

admin.nodeInfo.enode
admin.peers
personal.unlockAccount(eth.accounts[0])
eth.sendTransaction({from:eth.accounts[0], to: eth.accounts[1], value: 1, gas: 100000, gasPrice: 1})

admin.addPeer("enode://01bee8f3e8db6de17801bc7273e4171a5a20a136c23d39623337268118132acfe0adcdcc5e5df5f95b8f5d3c0933d632621a3a065cf9b5015a7e7806ee9b5903@127.0.0.1:30303?discport=0")
```



## VSC testing

```
{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [

        {
            "name": "Geth mainnet",
            "type": "go",
            "request": "launch",
            "mode": "debug",
            "program": "${workspaceFolder}/cmd/geth/",
            "args": [
            ],
        },

        {
            "name": "Launch cascadeth - peer 1",
            "type": "go",
            "request": "launch",
            "mode": "debug",
            "program": "${workspaceFolder}/cmd/geth/",
            "args": [
                "-networkid",
                "15",
                "-datadir",
                "C:\\Users\\Yann\\Documents\\data-cascade",
                "-port",
                "30303",
                "-unlock",
                "0x78161ecF55Dc59Bd9E9c5C6620c0eb2Ad3b4d555",
                "-mine",
                "-nodiscover",
                "-password",
                "C:\\Users\\Yann\\Documents\\pwd1.txt"
            ],
        },

        {
            "name": "Launch cascadeth - peer 2",
            "type": "go",
            "request": "launch",
            "mode": "debug",
            "program": "${workspaceFolder}/cmd/geth/",
            "args": [
                "-networkid",
                "15",
                "-datadir",
                "C:\\Users\\Yann\\Documents\\data-cascade-2",
                "-port",
                "30304",
                "-unlock",
                "0xBbd5695c790F13b470c44b5950311C8dd24f78E6",
                "-mine",
                "-nodiscover",
                "-ipcpath",
                "gethpipe.ipc",
                "-password",
                "C:\\Users\\Yann\\Documents\\pwd2.txt"
            ],
        }
    ]
}
```

### Midterm presentation



1. disco template
2. intro
3. problem statement
4. tldr slide
   1. cascade
   2. cascade and ethereum
   3. details
5. whats most important
6. what will be most important, what challenges remain